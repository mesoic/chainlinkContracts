Flux Monitor Implementation: The objective of this exercise is to create a minimal working example of the chainlink network by launching a cluster of nodes (n=3) and aggregating results of the API requests in an aggregator contract. The flux monitor contract to be used is: 

	AccessControlledAggregator.sol

In order to achieve this, an existing node infrastructure will be used. The first step is to update the node infrastructure, and to verify the functionality of the node. This is done via jobs which test liveness(cron), and via simple data requests through an existing external adapter (cryptoCompare). All infrastructure is deployed on the Ropsten testnet. Once the node is verified as functional, the existing infrastructure is expanded to the case of multiple nodes responding to an aggregator contract.

Summary of steps: 
	A) Update, review, and patch old node infrastructure 
	B) Verify functionality of node via on-chain data requests
	C) Decentralize data sources (add several data sources)
	D) Decentralize node infrastructure (design network architecture)
		- Development of chainlinkDeployer.py
	E) Deployment of AccessControlledAggregator.sol
		- Configure fluxmonitor jobSpecs on each node


A) Start old node infrastructure with updated chainlink version and patch database: 

	Having a maintainable testnet infrastructure in AWS is valuable because cloud instillations have better liveness properties. Being able to effectively wield AWS to run a node infrastructure is a major asset. A node is a dynamic entity with a temporal component, so you need it in the cloud to catch errors which occur with low frequency. Does it really work anon? Does it really flux the price consistently? Let's see.  	

	Update the basics and debug node infrastructure

		Update Linux AMI:
			sudo yum update (linux AMI)
			docker pull smartcontract/latest
			docker pull fiews/cl-eth-failover

		Get new fiews API key (7 day tiral):
			3TfOIyjgfTMgoEt8cyvuynqet9cWEdDtAdej3Wum 	

		Restart Postgres Database 

	Note: The node is configured to report to cloudWatch logs. Errors were encountered when starting the node

		1) 	{ "level": "error", "ts": 1614708904.2861276, "caller": "logger/default.go:139", "msg": "unable to lock ORM: dial tcp: lookup chainlink-postgres.cpkt4axduud7.eu-central-1.rds.amazonaws.com on 172.31.0.2:53: no such host", "stacktrace": }

			The reason for this was an incorrect endpioint configuration when starting the DB in the AWS console. The endpoint must be consistent with appears in the chainlink .env file.

		2) { "level": "fatal", "ts": 1614709795.4249516, "caller": "store/store.go:70", "msg": "Unable to initialize ORM: pq: invalid input value for enum run_status: \"pending_confirmations\"\nerror running }

			Recall from last time (restarting node - cold start), that we need to interact with the database in order to recover this error. 

				./scripts/chainlink-postgres.sh
				postgres=> \l
				postgres=> \c chainlinkropsten;
				chainlinkropsten=> \dt
				chainlinkropsten=> truncate heads cascade;
				chainlinkropsten=> truncate job_runs cascade;

	Login successful. Note that it appears that we cannot connect to the Ropsten chainlink explorer, so comment this out of the ".env" file. When starting the node, the existing configuration requests the ETHUSD price hourly to the cronConsumerContract.

	Recall:
	{
		OracleAddress 			: 0x38868083fb89b571c53d2765d453d2f90f51e196
		OracleContract 			: 0x5471030a14ea46a32f065ac226516723b429ec2b
		cronConsumerContract 	: 0x187b0774af793cf6d92735e809b7457fb355fea6
		ContractCreator 		: 0xebb230E499c1cB6883Bf6996576fFe9bd4D42fAc
	}


B) Verify consumerContract interaction with node via an external adapter.

	Now we want to test interaction through our cryptoCompare external adapter. Note that the cryptoCompare external adapter has been previously deployed via AWS Lambda.

	Recall: 
	{
		ccConsumerContract		: 0xb4302F5bFf79fEbe8e75a8fcB1A62C640A798271

	}

	Perform request: This requests jobId = 1060a4c63b62495b959968863553bd37, which fetches the price of LINK. The price of LINK is stored in contact variable "uint256 public data".


		npx truffle exec scripts/externalAdapter/request-externalAdapter.js --network ropsten
		Using network 'ropsten'.

		Creating request on contract: 0xb4302F5bFf79fEbe8e75a8fcB1A62C640A798271
		{
			  specId: '0x3130363061346336336236323439356239353939363838363335353362643337',
			  requester: '0xb4302F5bFf79fEbe8e75a8fcB1A62C640A798271',
			  requestId: '0x7b1863904a0d6c70e869659241d055bfa3ae23b99454d3ac13fb52ff6104f4c5',
			  payment: '0x016345785d8a0000',
			  callbackAddr: '0xb4302F5bFf79fEbe8e75a8fcB1A62C640A798271',
			  callbackFunc: '0x4357855e',
			  expiration: '0x603ea4f7',
			  data: <Buffer bf ff>,
			  dataVersion: 1,
			  topic: '0xd8d7ecc4800d25fa53ce0372f13a416d98907a7ef3d8d3bdd79cf4fe75529c65',
			  txHash: '0x75c74190fa2cdd76f5611cc143f9f4f69ed899f08b0d25fb67341ce2075d3e6b'
		}

	Verify result: next step is to read the value written to the consumer contract by the chainlink node(=27.68$)

		npx truffle exec scripts/externalAdapter/read-externalAdapter.js --network ropsten
		Using network 'ropsten'.

		2768000000
		Truffle v5.1.14 (core: 5.1.14)
		Node v12.20.0


C) Decentralizing data sources

	In order to perform meaningful aggregation, it is necessary to implement multiple external adapters. In this section, multiple external adapters are deployed in AWS in order to obtain the LINKUSD price. This is the first step towards preparing a viable node image which can be used to simulate on-chain aggregation from multiple data sources. 

	In my original node configuration, only the cryptoCompare adapter was deployed. This was done via AWS lambda and a configured API endpoint:

		(old) https://8ohf3vjoo0.execute-api.eu-central-1.amazonaws.com/adapters/cl-cc

	To enable aggregation, we add some additional external adapters to our node (bridges)	

		{
			coinGecko		: https://8ohf3vjoo0.execute-api.eu-central-1.amazonaws.com/adapters/coingecko-ea
			coinPaprika 	: https://8ohf3vjoo0.execute-api.eu-central-1.amazonaws.com/adapters/coinpaprika-ea
			cryptoCompare 	: https://8ohf3vjoo0.execute-api.eu-central-1.amazonaws.com/adapters/cryptocompare-ea
		}

	The API endpoints are verified in AWS, and jobSpecs are prepared in the chainlink node. 

		{
			coinGecko		: d38de8b842d045c28475cf573c7dfe33
			coinPaprika 	: eb731064e4e44b18a7613bbc99d60145
			cryptoCompare 	: 3b9831dba5d54f23a5f2bcbfe4e88414
		}

	Each adapter is then verified independently by calling a corresponding consumer contracts. It is important to verify that each data source is functional, prior deploying a proof of concept aggregator. 
	
		{ 
			coinGecko 		: 0xb27a109dbd57e006b33c2f88f74be5169a8b0deb4c43a811d6f89fc10cf5d1f9
			coinPaprika 	: 0x68646c5a36cb37bf6d87bb0599591f2c5f679e91c158b113269b2491a47792ae
			cryptoCompare 	: 0xbfe7a55b9395676daff5049577849ba053769b74caba03f5c210a82e1d2ecdff
		}


	Note on Copy Adapter: The old and new version of cryptocompare result was returned under data.USD. However, when porting the jobSpec for coinGecko and coinPaprika, job runs failed at <Multiply> with message:

		"cannot parse into big.Float: : can't convert to decimal:

	Comparing runs between adapters I noticed that, despite succeeding, <Copy> was returning "null" because the jobSpec was requesting data.USD on the returned JSON (which does not exist for those adapters). When "null" is passed, it cannot be parsed big.Float and then <Multiply> fails. In this case, the jobSpec <Copy> adapter must look for data.result for each respective job run. 


D) Decentralizing the network 

	In this step, the objective is to generalize our node architecture to accommodate the deployment of a decentralized network of chainlink nodes (n=3). The nodes will be implemented as a single AWS EC2 instance running separate docker containers for each node.

	D.1) Configuring AWS

		 It is useful to prepare a separate environment, so first we need to backup the current node environment in case we break something: 

			a) Create snapshot of RDS instance (for backup)
				- "chainlink-ropsten-030321"

			b) Create disk image of current setup "chainink-ropsten". 
				- This is the root of our new AMI fork "chainlink-flux-monitor"
			
			c) Create new "flux-monitor" EC2 instance 
				- Create new pem key for the instance (chainlink-flux-monitor.pem)
				- Create new elasticIP and associate with instance (3.121.16.220)
				- Add chainlink-logging-role to instance for cloud watch (Security > Modify IAM role) 
				- Add pem key, elastic IP to local scripts for mounting remote node (ssh,sshfs)
				- Verify the the current configuration works on the new instance image

			d) Back up external adapter configurations 
				- jobSpecs for each implemented external adapter (for unit testing)
				- bridge configurations for each adapter 

			e) Create a separate git-repository for the fluxMonitor work
				- Avoid confusion when working with scripts
			
	D.2) Developing chainlinkDeployer	

		After doing the above, we have a safe environment to work in. Next is to generalize our instance by running more than one node. The original fully-implemented and unit tested single node instance node was developed using a series of shell scripts. However, after working on the problem, it was decided to migrate the server side to python. This allows for better organization of data, greater automation, modular code, and symbolic deployment of nodes on the network. 

		Before proceeding, we need to create a new database for each node in our RDS instance.

			postgres=> CREATE ROLE mesoic WITH PASSWORD 'password' CREATEDB CREATEROLE LOGIN;
			postgres=> GRANT rds_superuser TO mesoic;

		We want to clone the master user. This allows us to perform DB manipulations and connect remotely without accidentally interacting with old configurations. Now we create some new tables. 

			postgres=> create database fluxnode0;
			postgres=> create database fluxnode1;
			postgres=> create database fluxnode2;

		Check the databases created (postgres=> \l)

			fluxnode0     | mesoic       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 
			fluxnode1     | mesoic       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 
			fluxnode2     | mesoic       | UTF8     | en_US.UTF-8 | en_US.UTF-8 | 

		Now we want to create a new node which points to each database. In order to do this, the node infrastructure was rewritten to facilitate quasi-automated deployment of nodes.

			https://github.com/mesoic/chainlinkDeployer

		The script generates of ".env" files and takes care of invoking the docker containers correctly (both on firstrun, and on ordinary run). After developing chainlinkDeployer, is is straightforward to generate a network of chainlink nodes as shown in "run-fluxmonitor.py": 

			CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES
			3df22d101a67        smartcontract/chainlink   "chainlink local node"   14 minutes ago      Up 12 minutes       0.0.0.0:6688->6688/tcp   fluxNode2
			4c66bfea8393        smartcontract/chainlink   "chainlink local node"   14 minutes ago      Up 14 minutes       0.0.0.0:6687->6688/tcp   fluxNode1
			b41e47082193        smartcontract/chainlink   "chainlink local node"   15 minutes ago      Up 14 minutes       0.0.0.0:6686->6688/tcp   fluxNode0
			c629898694bb        fiews/cl-eth-failover     "node index.js wss:/���"   15 minutes ago      Up 15 minutes       0.0.0.0:4000->4000/tcp   eaas-failover
						
		The network consists of 3 fully independent nodes, looking at common EaaS provider. In this step it is important to do the port forwarding correctly and to verify the address of each node on its respective port. With some ssh tunneling, it is possible to have the GUI each node in a separate tab in the browser so we can monitor job requests. 

	D.3) On-chain configuration	and testing

		After getting the instances running and configuring the networking, the final step is to deploy oracle contracts for each node. For each node, we deploy an oracle contract (Oracle.sol), and we point the contract to our node by calling "setFulfillmentPermission(address, true)". Note we could also transferOwnership of these oracle contracts to each respective node if desired. The point is to model the idea of three fully independent node operators as accurately as possible. 

		Using remix, we deploy three copies of Oracle.sol, and run setFulfillmentPermission(_address, true) on each contract. After doing the transactions, we can confirm permissions have been set via getAuthorizationStatus(_address). 

			{ 
				"fluxNode0" : { 
					"_address"	: "0x0296FB97aABe4550120EE5340d38f5FA8FA05d72",
					"_oracle"	: "0x9467b20a09122741c93d59808752f2e5559051cc"
				},
			
				"fluxNode1" : { 
					"_address"	: "0xbBEEf2F01bD0F3Eee0944bC46Db583Cf1db6C541",
					"_oracle"	: "0x3a5c66eb85290ad6b1a76baf30bc51805f3d2ab8"
				},

				"fluxNode2" : { 
					"_address"	: "0x3Cf7c9273b5fA06eB9E7b72D5FB4f6A349e898b3",
					"_oracle"	: "0x88d18c7436e21ffe862a73283e21e88676de197b"
				}
			}

		The final step is to add these oracle contract addresses to our configuration files in the chainlinkDeployer framework and restart the nodes. The oracle contract addresses should now be configured in the GUI.

			[ec2-user@ip-172-31-45-177 scripts]$ python stop-fluxmonitor.py
			[ec2-user@ip-172-31-45-177 scripts]$ python generate-env.py
			[ec2-user@ip-172-31-45-177 scripts]$ python start-fluxmonitor.py

		Additionally, it is necessary to fund the each node with some Ropsten ETH prior to testing external adapters. Note the on-chain steps can be seen at the following address:

			https://ropsten.etherscan.io/address/0xebb230e499c1cb6883bf6996576ffe9bd4d42fac


		Note that Ropsten ETH is available here with good reliability	
			https://faucet.dimensions.network/	

	D.4) Testing the nodes and deploying external adapters

		The final step in configuring our network is to add the external adapter configured in section (D) as bridges in each node and create job runs which test the functionality of adapter. A jobSpec is prepared to query the LINKUSD price through each adapter on all three nodes. 

			fluxNode0 : {
				coingecko-ea 		: 4c9502879677459681c32698add72105
				coinpaprika-ea 		: 8f3bc4026c364ba6987889dc7e3fd2a4
				cryptocompare-ea 	: ae5790c791964219a2a37bba62bdb884
			} 

			fluxNode1 : {
				coingecko-ea 		: bf9df7ccca874ec9926ef2b9726bff68
				coinpaprika-ea 		: f8cd7b2a32b0456dac623a610a15232e
				cryptocompare-ea 	: ff097e6713264beeb20d9ae5357b213b
			}


			fluxNode2 : {
				coingecko-ea 		: 86d054f982ca4b8ebac6dc65ecb1edc3
				coinpaprika-ea 		: 4c044f15f0af4322925c3800aa401ff8 
				cryptocompare-ea 	: d4f303ea587d4c338e1dd616ad32cda0
			}

			Note the following (occasinal) error on Ropsten
				TxHash 0x08ebc94f93eb54e42fb882927b4d711019f8918da705ab3e3f625c513872beda initiating 
				run ee038abf23b3446a84316d7b0b5c7828 not on main chain; presumably has been uncled
			
		Testing complete: 3(3) external adapters verified operational on 3(3) nodes.  

		All tests performed on consumer contract deployed at:	
			https://ropsten.etherscan.io/address/0xb4302F5bFf79fEbe8e75a8fcB1A62C640A798271


	D.5) Finalize this stage

		At this stage, all pieces are in place for implementing a minimum working example of a fluxMonitor price feed. Before continuing with fluxMonitor implementation, it is useful to back up all work:
			- Create AMI of EC2 instance 
			- Create Snapshot of RDS database
			- Push updated repositories to git
				
		Chainlink version issue: Noticed that chainlink is running v0.8.18, which (might) not have the fluxMonitor adapter. This is due "latest" pointing to 0.8.18. Will image with this version prior to attempting upgrade to v0.10.1.

			docker pull smartcontract/chainlink:0.10.1


E) Running a flux monitor 

	Now that we have a node that has some working external adapters. It is possible to create a flux monitor for a given piece of price data. For this it is useful to use the following article as a basis for reference material. 

		Flux Aggregator Contracts: The Technical Explanation
				https://news.reputation.link/article/27

	E.0) Understanding the deployment.
	
		For this we need two pieces. The contract, and jobSpecs. At this point, we have deployed three nodes, and have verified the operation of the coinGecko, coinPaprika, and cryptoCompare external adapters on EACH node by making deploying an Orcale.sol for each node, and requesting data through a simple consumer contract. 
		
		In principle the deployment of a feed should be quite straightforward. First is to deploy an aggregator contract (AccessControlledAggregator.sol). The contract must then be configured to point to the nodes on our network. After this, a jobSpec containing the fluxmonitor initiator must be deployed on each node. 

		Note the difference between standard data requests and aggregators:

			Standard Request. 
				- Deploy Oracle.sol and setFulfillmentPermission(_node, true)
				- Create RunLog jobSpec and point to address(Oracle.sol)
				- Create request through consumerContract.sol
				- Node fulfills the request through Oracle.sol

			Aggregator Request. 
				- Deploy AccessControlledAggregator.sol and changeOracles(_nodes)
				- Create fluxmonitor jobSpec and point to address(AccessControlledAggregator.sol)
				- Nodes monitor off-chain data in rounds 
				- Nodes submit new value to fluxmonitor when contract value deviates from off chain value

	E.1) Deploying the aggregator contract (AccessControlledAggregator.sol). 

		Here we use a flattened version of AccessControlledAggregator.sol available at
			https://github.com/keep3rb-network/peripheri-bsc/blob/main/AccessControlledAggregator.sol

		Some details on the contract compilation: 		

			{
				"name" : "AccessControlledAggregator.sol"
				"solc" 	: "v0.6.6+commit.6c089d02"
				"optimization"  : "Yes"
			}

		For initial values, we will use the example of the ETH/USD contract	
			https://etherscan.io/address/0x8cDE021F0BfA5f82610e8cE46493cF66AC04Af53#readContract


		We will deploy the contract using remix, taking careful note of the constructor

			/**
			   * @notice set up the aggregator with initial configuration
			   * @param _link The address of the LINK token
			   * @param _paymentAmount The amount paid of LINK paid to each oracle per submission, in wei (units of 10⁻¹⁸ LINK)
			   * @param _timeout is the number of seconds after the previous round that are
			   * allowed to lapse before allowing an oracle to skip an unfinished round
			   * @param _validator is an optional contract address for validating
			   * external validation of answers
			   * @param _minSubmissionValue is an immutable check for a lower bound of what
			   * submission values are accepted from an oracle
			   * @param _maxSubmissionValue is an immutable check for an upper bound of what
			   * submission values are accepted from an oracle
			   * @param _decimals represents the number of decimals to offset the answer by
			   * @param _description a short description of what is being reported
			   */
			  constructor(
			    address _link,
			    uint128 _paymentAmount,
			    uint32 _timeout,
			    address _validator,
			    int256 _minSubmissionValue,
			    int256 _maxSubmissionValue,
			    uint8 _decimals,
			    string memory _description
			  ) 

		A first attempt at calling the constructor:

			{
				"_link" 		 		: "0x20fe562d797a42dcb3399062ae9546cd06f63280"
				"_paymentAmount"	 	: "1000000000000000", 	# 0.001 LINK
				"_timeout"  			: "172800",				# From 0x8cDE	
				"_validator" 			: "0x0000000000000000000000000000000000000000",
				"_minSubmissionValue" 	: "1000000",			# 0.1x(multiply)  = $0.1				 
				"_maxSubmissionValue"	: "100000000000", 		# 1000x(multiply) = $1000eoy
 				"_decimals" 			: "8",					# multiply_adapter_value
				"_description" 			: "LINK/USD",			
			}

		Contract creation transaction hash:	
			https://ropsten.etherscan.io/tx/0xe2ec62c63da859994007ce29a83fd94a65f1cfad30012c936b4de23d025cd9d3

		Contract address: 
			https://ropsten.etherscan.io/address/0x51a29dba0ccd0b28005e6214895d713bee3f3900

		Note that it is a good idea to verify the contract source on Etherscan. For the ABI encoded constructor arguments (for verification), we look at the end "input data" on the transaction hash (and we see the plaintext 000000(_link) as the first argument, and copy and paste to the end of input data. 

			00000000000000000000000020fe562d797a42dcb3399062ae9546cd06f6328000000000000000000000000000000000000000000000000000038d7ea4c68000000000000000000000000000000000000000000000000000000000000002a300000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000f4240000000000000000000000000000000000000000000000000000000174876e8000000000000000000000000000000000000000000000000000000000000000008000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000000000000000000000000000000000000084c494e4b2f555344000000000000000000000000000000000000000000000000

		The verified contract is here:
			https://ropsten.etherscan.io/address/0x51a29dba0ccd0b28005e6214895d713bee3f3900#code


	E.2) Configuring the contract

		Here is the YFI/USD flux aggregator
			https://etherscan.io/address/0xAec0D77fdD6a2a34EC3eaF915260496Ae27f9D25

		Looking at the history we find two function calls
			> changeOracles	
			> addAccess
			> submit, submit, submit

		So we must call the "changeOracles"	function. 

		/**
		   * @notice called by the owner to remove and add new oracles as well as
		   * update the round related parameters that pertain to total oracle count
		   * @param _removed is the list of addresses for the new Oracles being removed
		   * @param _added is the list of addresses for the new Oracles being added
		   * @param _addedAdmins is the admin addresses for the new respective _added
		   * list. Only this address is allowed to access the respective oracle's funds
		   * @param _minSubmissions is the new minimum submission count for each round
		   * @param _maxSubmissions is the new maximum submission count for each round
		   * @param _restartDelay is the number of rounds an Oracle has to wait before
		   * they can initiate a round
		   */
		  function changeOracles(
		    address[] calldata _removed,
		    address[] calldata _added,
		    address[] calldata _addedAdmins,
		    uint32 _minSubmissions,
		    uint32 _maxSubmissions,
		    uint32 _restartDelay
		  )

		Looking at the LINK/USD flux aggretator from before, we have that the "oracles" are addresses (not Oracle.sol contracts). The addresses contain only ETH, so we infer that the oracleAddress is what we need to input into the contract. 

			_removed:
				[]	(unless we make a mistake and need to edit the oracle list)
			_added:
				["0x0296FB97aABe4550120EE5340d38f5FA8FA05d72", "0xbBEEf2F01bD0F3Eee0944bC46Db583Cf1db6C541", "0x3Cf7c9273b5fA06eB9E7b72D5FB4f6A349e898b3"]
  	
		In the LINK/USD contract, _addedAdmins contain either addresses or contracts which have outflows of LINK. Basically, for a given oracle(n), _addedAdmins(n) can withdraw LINK from the aggregator for work done by _added(n). For our decentralized oracle testnet, we will create some new metamask addresses (Account10, Account11, Account12) to be admins for each oracle. 

			_addedAdmins:
				["0x278F238Af29ada967C819132104a63829f13aeb6", "0x8D9e56Ca40F27e6c391f044395890ecD7EDe1288", "0xce04ec5656aC7421C97eFB2dfB09fDB657CCB716"]

		For _minimumSubmissions, maximumSubmissions, _restartDelay:		

			_minSubmissions = 2 (requires _minSubmissions > 1, for basic decentralization) 	 
			_maxSubmissions = 3 (_maxSubmissions = number of oracles on the aggregator )
			_restartDelay 	= 1 (should be less than _minimumSubmissions)

		Note that in the LINK/USD aggregator we have:

			_minSubmissions = 8
			_maxSubmissions = 15
			_restartDelay 	= 3
			
		So our final arguments for changeOracles() are

			{
				"_removed" 			: []
				"_added"			: ["0x0296FB97aABe4550120EE5340d38f5FA8FA05d72", "0xbBEEf2F01bD0F3Eee0944bC46Db583Cf1db6C541", "0x3Cf7c9273b5fA06eB9E7b72D5FB4f6A349e898b3"]
				"_addedAdmins" 		: ["0x278F238Af29ada967C819132104a63829f13aeb6", "0x8D9e56Ca40F27e6c391f044395890ecD7EDe1288", "0xce04ec5656aC7421C97eFB2dfB09fDB657CCB716"]
				"_minSubmissions" 	: "2"	
				"_maxSubmissions" 	: "3"
				"_restartDelay"		: "1"
			}	

		Note that "changeOracles()" in "AccessControlledAggregator.sol" is analogous to "setFulfillmentPermission()" in "Oracle.sol". Before doing the transaction, we should transfer some Ropsten LINK to the contract. Note that the changeOracles() function checks if the balance of the contract exceeds the reserve and will revert if there is no LINK. 

			https://ropsten.etherscan.io/tx/0x50bfa70b946386b0ed4e3e8df8860196f01ae35e224ca4dcd02cee8e9602d72e

		Run the updateAvailableFunds() function to update the "availableFunds" state variable 

			https://ropsten.etherscan.io/tx/0x1dd167e182726a25342ad37704536f6ed76f343e8ef12376afae9bc72113bcea

		And then run changeOracles() with the arguments shown above:

			https://ropsten.etherscan.io/tx/0x4f4301aafe9448aeec1bacf128fe07458b8ac3ebe48a28e2da43a905b36c7f57

		Lastly, we need to handle addAccess()
		
		/**
		 * @notice Adds an address to the access list
		 * @param _user The address to add
		 */
		function addAccess(address _user)
		  external
		  onlyOwner()
		{
		  if (!accessList[_user]) {
		    accessList[_user] = true;

		    emit AddedAccess(_user);
		  }
		}

		There is some variation in how addAccess is configured on various aggregators do not contain such a configuration. We use the AAVE/USD example because it is the simplest to interpret. Here is the AAVE/USD flux aggregator:

			https://etherscan.io/address/0xF2d87E37EA1e54c7Aa913d2447A5f69f61C114Cf

		Looking at the addAccess() transaction, which is called after changeOracles():
		
			https://etherscan.io/tx/0xb322fdbff565bf62fe48cb228dec0625ffaa29e049165d16ea6098a1bc05989c

		We see that an EACAggregatorProxy() contract has been configured.

			https://etherscan.io/address/0x547a514d5e3769680ce22b2361c10ea13619e8a9

		Copying the contract code, we can compile the contract in remix and deploy our own version. Note the constructor arguments in the AAVE/USD EACAggregatorProxy (which we infer from etherscan contractCreation transaction):

			_AGGREGATOR 		= 0xf2d87e37ea1e54c7aa913d2447a5f69f61c114cf
			_ACCESSCONTROLLER 	= 0x0000000000000000000000000000000000000000

		Replacing _AGGREGATOR with our own aggregator, we can deploy the EACAggregatorProxy()
		
			https://ropsten.etherscan.io/tx/0x272cbb6e9686bf523b223bfac74201a1ce4eefa8fc08cfa644bcfb8e76899193	

		Note the contact address of our proxy:
		
			https://ropsten.etherscan.io/address/0xb359cc819b1e11c40b108d029828a15082fa99c8	

		We will also go ahead and verify the contract code with our ABI encoded constructor arguments:

			00000000000000000000000051a29dba0ccd0b28005e6214895d713bee3f39000000000000000000000000000000000000000000000000000000000000000000

		And now we can go ahead and run addAccess() on our AccessControlledAggregator.sol:
		
			https://ropsten.etherscan.io/tx/0xbc37acda7e78358823a805b40198d06351325aefd1605e36b506e37cf9a65112	

		At this point the setup should be completely consistent with production AccessControlledAggregator.sol contracts


	E.3) Creating the jobSpecs and monitoring a price feed.

		The final step is to point the chainlink nodes in our network to our newly configured aggregator contract. Example JobSpecs for fluxMonitor jobs with external adapters are available in the chainlink core repo. fluxMonitor jobs are analogous to cron insofar as the node initiates interaction with a contract on it's own behalf. 

			chainlink/core/internal/testdata/flux_monitor_job.json
			chainlink/core/web/testdata/flux_monitor_bridge_job.json
			chainlink/core/web/testdata/flux_monitor_job.json

		Additional guidance on creating the jobSpec is available here:

			https://news.reputation.link/article/27

		Prior to adding the jobSpecs to each node, it is a good idea to test that the nodes are working properly by doing a few standard data requests through our consumer contract (externalAdapter.sol).

			npx truffle exec scripts/fluxMonitor/request-externalAdapter.js --network ropsten

		Note, we must add the following to chainlinkDeployer
		
			"FEATURE_FLUX_MONITOR"		: "true"
	
		Note the fluxmonitor jobIds (threshold=1):	This was far too aggessive it seems (the on-chain state was being updated every minute). which consumes lots of test ETH). In order to get something reasonable, we can set the polling time to 1h. This will not pick up high frequency moves in the market, but it helps with the threshold issue. 
		{
			fluxnode0 : 2ddf1fc311bb49e398dd05e440643805
			fluxNode1 :	04c186437e3e4a71b5e3ed268bbab676
			fluxNode2 : 1cddcba830e6445c85a1bdf44f3723ff
		}

		Note that each node is configured to query a different subset (size=2) of our external adapters. This models decentralization of data, and ensures that the aggregation to an accurate single value is occurring as designed. It is set up in the following way: 

			AccessControlledAggregator
			|	fluxNode0[coinGecko, coinPaprika]  		
			|	fluxNode1[coinPaprika, crytoCompare]	
			|	fluxNode2[coinGecko, crytocompare] 	 	


F) Final comment

	The implementation of a fluxmonitor and aggregator contracts represents a minimum viable decentralized oracle network. Within the generalization to multiple nodes and multiple data sources, all basic of the chainlink network are present. 	